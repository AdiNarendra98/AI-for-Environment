{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Include the command line instructions for preparing the splits\n",
    "  - Possibly include a parameter for testing (just a few tiffs)\n",
    "    - Is this tiff failing to reproject? LE07_147038_20080701.tif\n",
    "  - !bash scripts/geo/setup_data.sh\n",
    "  - Include as actual code block\n",
    "* argument to notebook: what are the train / dev / test folders?\n",
    "  - where do we save the checkpoints?\n",
    "  - Where do we save the logs\n",
    "  - Where do we save the final accuracy\n",
    "* plot the data right before training (a few random slices)\n",
    "* Call the train script as a bash command\n",
    "  - !python3 -m train\n",
    "* Load the summarywriter that has been saved, look at some predictions\n",
    "* Load some of the checkpoints\n",
    "  - Visualize predictions from them\n",
    "  - Visualize predictions on tiffs within train / test?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some parameters for the notebook\n",
    "import yaml\n",
    "params = yaml.safe_load(open(\"geo.yaml\", \"r\"))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /mnt/blobfuse/glaciers/expers/geographic/masks # remove any masks files that might exist\n",
    "!bash ../geo/setup_data.sh test # create geographic splits data in test mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've setup the geographic splits, let's look at some example training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import numpy\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "params[\"split_dir\"] = \"/mnt/blobfuse/glaciers/expers/geographic/splits/1\"\n",
    "params[\"split_dir\"] = pathlib.Path(params[\"split_dir\"])\n",
    "train_ims = list((params[\"split_dir\"] / \"train\").glob(\"*img*npy\"))\n",
    "test_ims = list((params[\"split_dir\"] / \"test\").glob(\"*img*npy\"))\n",
    "dev_ims = list((params[\"split_dir\"] / \"dev\").glob(\"*img*npy\"))\n",
    "\n",
    "K = 5\n",
    "_, ax = plt.subplots(2, K, figsize=(15, 15))\n",
    "for i, im in enumerate(random.sample(train_ims, k=K)):\n",
    "    x = np.load(im)\n",
    "    y = np.load(str(im).replace(\"img\", \"mask\"))\n",
    "    ax[0, i].imshow(x)\n",
    "    ax[1, i].imshow(y)\n",
    "    \n",
    "    \n",
    "plt.subplots_adjust(wspace=.05, hspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below visualizes which slices are included in the training, development, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "params[\"slices_geojson\"] = \"/mnt/blobfuse/glaciers/expers/geographic/slices/slices.geojson\"\n",
    "slices_meta = gpd.read_file(params[\"slices_geojson\"])\n",
    "slices_meta\n",
    "\n",
    "slices_meta[\"train_type\"] = \"\"\n",
    "train_str = [str(s.stem) for s in train_ims]\n",
    "dev_str = [str(s.stem) for s in dev_ims]\n",
    "test_str = [str(s.stem) for s in test_ims]\n",
    "\n",
    "for row in slices_meta.iterrows():\n",
    "    cur_slice = pathlib.Path(row[1][2]).stem\n",
    "    if cur_slice in train_str:\n",
    "        slices_meta.loc[row[0], \"train_type\"] = \"train\"\n",
    "    elif cur_slice in dev_str:\n",
    "        slices_meta.loc[row[0], \"train_type\"] = \"dev\"\n",
    "    elif cur_slice in test_str:\n",
    "        slices_meta.loc[row[0], \"train_type\"] = \"test\"\n",
    "\n",
    "slices_meta.plot(column=\"train_type\", legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run training and look at the resulting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../train.py -d /mnt/blobfuse/glaciers/expers/geographic/splits/1/ -c ../../conf/train.yaml  -p /mnt/blobfuse/glaciers/expers/geographic/splits/1/postprocess.yaml -r geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=/mnt/blobfuse/glaciers/expers/geographic/splits/1/runs/geo/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
